# -*- coding: utf-8 -*-
"""fourmodels_testdatasets-sjg.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/asundar0128/9db7458dfe4aa91b9c5be13bc2cacd8c/fourmodels_testdatasets-sjg.ipynb
"""

!git clone https://github.com/asundar0128/IndependentStudy.git

!pip install -q transformers bitsandbytes accelerate pandas matplotlib scikit-learn tqdm datasets huggingface_hub

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

!pip install --upgrade openai

!pip install --upgrade bitsandbytes transformers accelerate

!pip install -U bitsandbytes
!pip install -U transformers accelerate

"""PFRED Dataset - Galactica-6.7B"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from sklearn.metrics import mean_squared_error, r2_score

generatedInputCSV = "/content/PFRED.csv"
generatedOutputCSV = "/content/pfred_galactica67b_zeroshot_valid_only.csv"
generatedMetrics = "/content/pfred_galactica67b_zeroshot_metrics.txt"
generatedPlotPath = "/content/pfred_galactica67b_zeroshot_plot.png"
generatedInvalidRows = "/content/pfred_zeroshot_invalid_rows.csv"
generatedModelName = "facebook/galactica-6.7b"
generatedMaximumTokens = 48
generatedOffloadDirectory = "/tmp/offload"

generatedAccessionMap = {
    "X62295": "Rattus mRNA for vascular type-1 angiotensin II receptor",
    "XM_051583": "Homo sapiens v-raf-1 murine leukemia viral oncogene homolog 1 (RAF1), mRNA",
    "M14758": "Homo sapiens P-glycoprotein (PGY1) mRNA",
    "NM_004996": "Homo sapiens ATP-binding cassette (ABCC1), mRNA",
    "M24283": "Human intercellular adhesion molecule-1 (ICAM-1)",
    "X52479": "Human PKC alpha mRNA",
    "NM_001078": "Homo sapiens VCAM1, transcript variant 1, mRNA",
    "XM_057446": "Homo sapiens SELE mRNA",
    "M30640": "ELAM1 mRNA, complete cds",
    "NM_000877": "Homo sapiens IL1R1 mRNA",
    "M31585": "Mouse ICAM-1 mRNA",
    "BC036531": "Homo sapiens collagen, type I, alpha 1, mRNA",
    "NM_010784": "Mus musculus midkine (Mdk), mRNA",
    "M15077": "Firefly luciferase gene",
    "X03484": "Human raf oncogene mRNA",
    "X14805": "Mus musculus DNA methyltransferase 1",
    "BC005976": "Homo sapiens RhoA mRNA",
    "M10843": "Rabbit beta-globin mRNA",
    "U45880": "XIAP mRNA",
    "AF015950": "Human telomerase reverse transcriptase mRNA",
    "NR_001566": "Human telomerase RNA component (TERC)",
    "M34309": "HER3 mRNA",
    "NM_004507": "HUS1 mRNA",
    "AJ278710": "E. coli 23S rRNA gene",
    "X03363": "Human c-erb-B-2 mRNA",
    "M10988": "Human TNF mRNA",
    "NM_000791": "DHFR mRNA",
    "NM_001168": "BIRC5 mRNA",
    "NM_013642": "Mus musculus Dusp1 mRNA",
    "AF025846": "Co-reporter vector pRL-TK"
}

def generatedSanitizedSequence(generatedSequenceValue):
    return str(generatedSequenceValue).strip()

def generatedPredictionValue(generatedTextValue):
    generatedLines = generatedTextValue.strip().splitlines()
    for generatedLine in generatedLines:
        generatedMatchesValues = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLine)
        for generatedMatchValue in generatedMatchesValues:
            try:
                generatedValue = float(generatedMatchValue)
                if 0 <= generatedValue <= 1:
                    return round(generatedValue, 4)
            except:
                continue
    return np.nan

def generatedZeroShotPrompt(generatedRowValue):
    generatedGeneSequence = generatedAccessionMap.get(generatedRowValue["Accession"], "a specific gene")
    generatedSequenceValue = generatedSanitizedSequence(generatedRowValue["DNA Sequence"])
    return (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
        f"Target gene: {generatedGeneSequence}\n[START_DNA]{generatedSequenceValue}[END_DNA]\nPredicted inhibition efficacy:"
    )

generatedBITSBytesConfig = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,
    offload_state_dict=True
)

generatedTokenizer = AutoTokenizer.from_pretrained(generatedModelName)
generatedTokenizer.pad_token = generatedTokenizer.eos_token
generatedPadTokenID = generatedTokenizer.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="cuda",
    quantization_config=generatedBITSBytesConfig,
    offload_folder=generatedOffloadDirectory
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["DNA Sequence", "Efficacy"])
generatedDataFrame = generatedDataFrame[generatedDataFrame["Accession"].isin(generatedAccessionMap)].reset_index(drop=True)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPrompt = generatedZeroShotPrompt(generatedRowValue)
        generatedInputsValue = generatedTokenizer(generatedPrompt, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizer.eos_token_id
        )

        generatedDecodedValue = generatedTokenizer.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPrompt
        generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {e}] Prediction: {generatedParsedValue} → {generatedDecodedValue.strip()}")

        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[e, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])
generatedActualLabels = np.clip(generatedValidDataFrame["Efficacy"].values, 0, 1)
generatedPredictionLabels = np.clip(generatedValidDataFrame["Predicted_Efficacy"].values, 0, 1)

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0
generatedR2Value = max(0.0, min(1.0, generatedR2Value))

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("Galactica-6.7B Zero-Shot: Predicted vs True Efficacy")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)

generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

import pandas as pd
from sklearn.metrics import r2_score

generatedDataFrame = pd.read_csv("/content/pfred_galactica67b_zeroshot_valid_only.csv")

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])

generatedActualLabel = generatedValidDataFrame["Efficacy"].values
generatedPredictionLabel = generatedValidDataFrame["Predicted_Efficacy"].values

generatedR2ScoreValue = r2_score(generatedActualLabel, generatedPredictionLabel)
print(f"Unclipped R² score: {generatedR2ScoreValue:.4f}")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, random, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig

generatedInputCSV = "/content/PFRED.csv"
generatedOutputCSV = "/content/pfred_galactica67b_fewshot_valid_only.csv"
generatedMetrics = "/content/pfred_galactica67b_fewshot_metrics.txt"
generatedPlotPath = "/content/pfred_galactica67b_fewshot_plot.png"
generatedInvalidRows = "/content/pfred_fewshot_invalid_rows.csv"
generatedModelName = "facebook/galactica-6.7b"
generatedMaximumTokens = 48
numberFewShot = 3
generatedOffloadDirectory = "/tmp/offload"

generatedAccessionMap = {
    "X62295": "Rattus mRNA for vascular type-1 angiotensin II receptor",
    "XM_051583": "Homo sapiens v-raf-1 murine leukemia viral oncogene homolog 1 (RAF1), mRNA",
    "M14758": "Homo sapiens P-glycoprotein (PGY1) mRNA",
    "NM_004996": "Homo sapiens ATP-binding cassette (ABCC1), mRNA",
    "M24283": "Human intercellular adhesion molecule-1 (ICAM-1)",
    "X52479": "Human PKC alpha mRNA",
    "NM_001078": "Homo sapiens VCAM1, transcript variant 1, mRNA",
    "XM_057446": "Homo sapiens SELE mRNA",
    "M30640": "ELAM1 mRNA, complete cds",
    "NM_000877": "Homo sapiens IL1R1 mRNA",
    "M31585": "Mouse ICAM-1 mRNA",
    "BC036531": "Homo sapiens collagen, type I, alpha 1, mRNA",
    "NM_010784": "Mus musculus midkine (Mdk), mRNA",
    "M15077": "Firefly luciferase gene",
    "X03484": "Human raf oncogene mRNA",
    "X14805": "Mus musculus DNA methyltransferase 1",
    "BC005976": "Homo sapiens RhoA mRNA",
    "M10843": "Rabbit beta-globin mRNA",
    "U45880": "XIAP mRNA",
    "AF015950": "Human telomerase reverse transcriptase mRNA",
    "NR_001566": "Human telomerase RNA component (TERC)",
    "M34309": "HER3 mRNA",
    "NM_004507": "HUS1 mRNA",
    "AJ278710": "E. coli 23S rRNA gene",
    "X03363": "Human c-erb-B-2 mRNA",
    "M10988": "Human TNF mRNA",
    "NM_000791": "DHFR mRNA",
    "NM_001168": "BIRC5 mRNA",
    "NM_013642": "Mus musculus Dusp1 mRNA",
    "AF025846": "Co-reporter vector pRL-TK"
}

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(generatedTextSequence):
    generatedMatches = re.findall(r"\b(0?\.\d{1,4}|1\.0+?)\b", generatedTextSequence)
    for generatedMatch in generatedMatches:
        try:
            generatedValidation = float(generatedMatch)
            if 0 <= generatedValidation <= 1:
                return round(generatedValidation, 4)
        except:
            continue
    return np.nan

def generatedFewShotBuilding(generatedTestRow, generatedFewShotDataFrame):
    generatedFewShotExamples = generatedFewShotDataFrame.sample(n=numberFewShot)
    generatedPrompt = (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
    )

    for _, generatedFewShot in generatedFewShotExamples.iterrows():
        generatedSequence = generatedSanitizedSequence(generatedFewShot["DNA Sequence"])
        generatedGeneDescription = generatedAccessionMap.get(generatedFewShot["Accession"], "a specific gene")
        generatedLabel = float(generatedFewShot["Efficacy"])
        generatedPrompt += f"Target gene: {generatedGeneDescription}\n[START_DNA]{generatedSequence}[END_DNA]\nPredicted inhibition efficacy: {generatedLabel:.2f}\n\n"

    generatedTestSequence = generatedSanitizedSequence(generatedTestRow["DNA Sequence"])
    generatedTestingGene = generatedAccessionMap.get(generatedTestRow["Accession"], "a specific gene")
    generatedPromptValue += f"Target gene: {generatedTestingGene}\n[START_DNA]{generatedTestSequence}[END_DNA]\nPredicted inhibition efficacy:"
    return generatedPromptValue

generatedBITSBytesConfig = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,
    offload_state_dict=True
)

generatedTokenizer = AutoTokenizer.from_pretrained(generatedModelName)
generatedTokenizer.pad_token = generatedTokenizer.eos_token
generatedPadTokenID = generatedTokenizer.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="cuda",
    quantization_config=generatedBITSBytesConfig,
    offload_folder=generatedOffloadDirectory
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["DNA Sequence", "Efficacy"])
generatedDataFrame = generatedDataFrame[generatedDataFrame["Accession"].isin(generatedAccessionMap)].reset_index(drop=True)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for a, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedFewShotPool = generatedDataFrame.drop(index=i)
        if len(generatedFewShotPool) < numberFewShot:
            continue

        generatedPrompt = generatedFewShotBuilding(generatedRowValue, generatedFewShotPool)
        generatedInputsValue = generatedTokenizer(generatedPrompt, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizer.eos_token_id
        )

        generatedDecodedValue = generatedTokenizer.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[a, "Prompt"] = generatedPrompt
        generatedDataFrame.at[a, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[a, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {a}] Prediction: {generatedParsedValue} → {generatedDecodedValue.strip()}")

        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[i, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[i, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])
generatedActualLabels = np.clip(generatedValidDataFrame["Efficacy"].values, 0, 1)
generatedPredictionLabels = np.clip(generatedValidDataFrame["Predicted_Efficacy"].values, 0, 1)

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0
generatedR2Value = max(0.0, min(1.0, generatedR2Value))

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("Galactica-6.7B Few-Shot: Predicted vs True Efficacy")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)

generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidLogPath, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidLogPath}")

import pandas as pd
from sklearn.metrics import r2_score

generatedDataFrame = pd.read_csv("/content/pfred_galactica67b_fewshot_valid_only.csv")

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])

generatedActualLabel = generatedValidDataFrame["Efficacy"].values
generatedPredictionLabel = generatedValidDataFrame["Predicted_Efficacy"].values

generatedR2ScoreValue = r2_score(generatedActualLabel, generatedPredictionLabel)
print(f"Unclipped R² score: {generatedR2ScoreValue:.4f}")

"""PFRED Dataset - LLaMA2-7b"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import login
from sklearn.metrics import mean_squared_error, r2_score

generatedInputCSV = "/content/PFRED.csv"
generatedOutputCSV = "/content/pfred_llama27b_zeroshot_valid_only.csv"
generatedMetrics = "/content/pfred_llama27b_zeroshot_metrics.txt"
generatedPlotPath = "/content/pfred_llama27b_zeroshot_plot.png"
generatedInvalidRows = "/content/pfred_llama27b_zeroshot_invalid_rows.csv"
generatedModelName = "meta-llama/Llama-2-7b-hf"
generatedMaximumTokens = 48

generatedAccessionMap = {
    "X62295": "Rattus mRNA for vascular type-1 angiotensin II receptor",
    "XM_051583": "Homo sapiens v-raf-1 murine leukemia viral oncogene homolog 1 (RAF1), mRNA",
    "M14758": "Homo sapiens P-glycoprotein (PGY1) mRNA",
    "NM_004996": "Homo sapiens ATP-binding cassette (ABCC1), mRNA",
    "M24283": "Human intercellular adhesion molecule-1 (ICAM-1)",
    "X52479": "Human PKC alpha mRNA",
    "NM_001078": "Homo sapiens VCAM1, transcript variant 1, mRNA",
    "XM_057446": "Homo sapiens SELE mRNA",
    "M30640": "ELAM1 mRNA, complete cds",
    "NM_000877": "Homo sapiens IL1R1 mRNA",
    "M31585": "Mouse ICAM-1 mRNA",
    "BC036531": "Homo sapiens collagen, type I, alpha 1, mRNA",
    "NM_010784": "Mus musculus midkine (Mdk), mRNA",
    "M15077": "Firefly luciferase gene",
    "X03484": "Human raf oncogene mRNA",
    "X14805": "Mus musculus DNA methyltransferase 1",
    "BC005976": "Homo sapiens RhoA mRNA",
    "M10843": "Rabbit beta-globin mRNA",
    "U45880": "XIAP mRNA",
    "AF015950": "Human telomerase reverse transcriptase mRNA",
    "NR_001566": "Human telomerase RNA component (TERC)",
    "M34309": "HER3 mRNA",
    "NM_004507": "HUS1 mRNA",
    "AJ278710": "E. coli 23S rRNA gene",
    "X03363": "Human c-erb-B-2 mRNA",
    "M10988": "Human TNF mRNA",
    "NM_000791": "DHFR mRNA",
    "NM_001168": "BIRC5 mRNA",
    "NM_013642": "Mus musculus Dusp1 mRNA",
    "AF025846": "Co-reporter vector pRL-TK"
}

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(generatedTextValue):
    generatedLines = generatedTextValue.strip().splitlines()
    for generatedLine in generatedLines:
        generatedMatchesValue = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLine)
        for generatedMatchValue in generatedMatchesValue:
            try:
                generatedValue = float(generatedMatchValue)
                if 0 <= generatedValue <= 1:
                    return round(generatedValue, 4)
            except:
                continue
    return np.nan

def generatedZeroShotPrompt(generatedRowValue):
    generatedGeneSequence = generatedAccessionMap.get(generatedRowValue["Accession"], "a specific gene")
    generatedSequence = generatedSanitizedSequence(generatedRowValue["DNA Sequence"])
    return (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
        f"Target gene: {generatedGeneSequence}\n[DNA_START]{generatedSequence}[DNA_END]\nPredicted inhibition efficacy:"
    )

generatedTokenizer = AutoTokenizer.from_pretrained(generatedModelName, use_auth_token=True)
generatedTokenizer.pad_token = generatedTokenizer.eos_token
generatedPadTokenID = generatedTokenizer.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="auto",
    torch_dtype=torch.float16,
    use_auth_token=True
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["DNA Sequence", "Efficacy"])
generatedDataFrame = generatedDataFrame[generatedDataFrame["Accession"].isin(generatedAccessionMap)].reset_index(drop=True)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedZeroShotPrompt(generatedRowValue)
        generatedInputs = generatedTokenizer(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputs.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputs,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizer.eos_token_id
        )

        generatedDecodedValue = generatedTokenizer.decode(generatedOutputsValue[0][generatedInputs["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {e}] Prediction: {generatedParsedValue} → {generatedDecodedValue.strip()}")
        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[e, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])
generatedActualLabels = generatedValidDataFrame["Efficacy"].values
generatedPredictionLabels = generatedValidDataFrame["Predicted_Efficacy"].values

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0
print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("LLaMA2-7B Zero-Shot: Predicted vs True Efficacy")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)

generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, random, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM
from huggingface_hub import login
from sklearn.metrics import mean_squared_error, r2_score

generatedInputCSV = "/content/PFRED.csv"
generatedOutputCSV = "/content/pfred_llama27b_fewshot_valid_only.csv"
generatedMetrics = "/content/pfred_llama27b_fewshot_metrics.txt"
generatedPlotPath = "/content/pfred_llama27b_fewshot_plot.png"
generatedInvalidRows = "/content/pfred_llama27b_fewshot_invalid_rows.csv"
generatedModelName = "meta-llama/Llama-2-7b-hf"
generatedMaximumTokens = 48
generatedNumShots = 3

generatedAccessionMap = {
    "X62295": "Rattus mRNA for vascular type-1 angiotensin II receptor",
    "XM_051583": "Homo sapiens v-raf-1 murine leukemia viral oncogene homolog 1 (RAF1), mRNA",
    "M14758": "Homo sapiens P-glycoprotein (PGY1) mRNA",
    "NM_004996": "Homo sapiens ATP-binding cassette (ABCC1), mRNA",
    "M24283": "Human intercellular adhesion molecule-1 (ICAM-1)",
    "X52479": "Human PKC alpha mRNA",
    "NM_001078": "Homo sapiens VCAM1, transcript variant 1, mRNA",
    "XM_057446": "Homo sapiens SELE mRNA",
    "M30640": "ELAM1 mRNA, complete cds",
    "NM_000877": "Homo sapiens IL1R1 mRNA",
    "M31585": "Mouse ICAM-1 mRNA",
    "BC036531": "Homo sapiens collagen, type I, alpha 1, mRNA",
    "NM_010784": "Mus musculus midkine (Mdk), mRNA",
    "M15077": "Firefly luciferase gene",
    "X03484": "Human raf oncogene mRNA",
    "X14805": "Mus musculus DNA methyltransferase 1",
    "BC005976": "Homo sapiens RhoA mRNA",
    "M10843": "Rabbit beta-globin mRNA",
    "U45880": "XIAP mRNA",
    "AF015950": "Human telomerase reverse transcriptase mRNA",
    "NR_001566": "Human telomerase RNA component (TERC)",
    "M34309": "HER3 mRNA",
    "NM_004507": "HUS1 mRNA",
    "AJ278710": "E. coli 23S rRNA gene",
    "X03363": "Human c-erb-B-2 mRNA",
    "M10988": "Human TNF mRNA",
    "NM_000791": "DHFR mRNA",
    "NM_001168": "BIRC5 mRNA",
    "NM_013642": "Mus musculus Dusp1 mRNA",
    "AF025846": "Co-reporter vector pRL-TK"
}

def generatedSanitizedSequence(generatedSequenceValue):
    return str(generatedSequenceValue).strip()

def generatedPredictionValue(text):
    generatedLinesValue = text.strip().splitlines()
    for generatedLineValue in generatedLinesValue:
        generatedMatches = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", line)
        for generatedMatch in generatedMatches:
            try:
                generatedValidation = float(generatedMatch)
                if 0 <= generatedValidation <= 1:
                    return round(generatedValidation, 4)
            except:
                continue
    return np.nan

def generatedFewShotPrompt(generatedTestRow, generatedDataFrame):
    generatedShotsDataFrame = generatedDataFrame.drop(index=generatedTestRow.name).sample(n=generatedNumShots)
    generatedPromptValue = (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
    )
    for _, generatedShotValue in generatedShotsDataFrame.iterrows():
        generatedGeneValue = generatedAccessionMap.get(generatedShotValue["Accession"], "a specific gene")
        generatedSequenceValue = generatedSanitizedSequence(generatedShotValue["DNA Sequence"])
        generatedEfficacyValue = round(float(generatedShotValue["Efficacy"]), 4)
        generatedPromptValue += f"Target gene: {generatedGeneValue}\n[DNA_START]{generatedSequenceValue}[DNA_END]\nPredicted inhibition efficacy: {generatedEfficacyValue}\n\n"
    generatedGeneValue = generatedAccessionMap.get(generatedTestRow["Accession"], "a specific gene")
    generatedSequenceValue = generatedSanitizedSequence(generatedTestRow["DNA Sequence"])
    generatedPromptValue += f"Target gene: {generatedGeneValue}\n[DNA_START]{generatedSequenceValue}[DNA_END]\nPredicted inhibition efficacy:"
    return generatedPromptValue

generatedTokenizer = AutoTokenizer.from_pretrained(generatedModelName, use_auth_token=True)
generatedTokenizer.pad_token = generatedTokenizer.eos_token
generatedPadTokenID = generatedTokenizer.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="auto",
    torch_dtype=torch.float16,
    use_auth_token=True
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["DNA Sequence", "Efficacy"])
generatedDataFrame = generatedDataFrame[generatedDataFrame["Accession"].isin(generatedAccessionMap)].reset_index(drop=True)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedFewShotPrompt(generatedRowValue, generatedDataFrame)
        generatedInputs = generatedTokenizer(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputs.pop("token_type_ids", None)

        generatedOutputs = generatedModelValue.generate(
            **generatedInputs,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizer.eos_token_id
        )

        generatedDecodedValue = generatedTokenizer.decode(generatedOutputs[0][generatedInputs["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {i}] Prediction: {generatedParsedValue} → {generatedDecodedValue.strip()}")
        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[e, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])
generatedActualLabels = np.clip(generatedValidDataFrame["Efficacy"].values, 0, 1)
generatedPredictionLabels = np.clip(generatedValidDataFrame["Predicted_Efficacy"].values, 0, 1)

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0
generatedR2Value = max(0.0, min(1.0, generatedR2Value))

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("LLaMA2-7B Few-Shot: Predicted vs True Efficacy")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)

generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

import pandas as pd
from sklearn.metrics import r2_score

generatedDataFrame = pd.read_csv("/content/pfred_llama27b_fewshot_valid_only.csv")

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])

generatedActualLabel = generatedValidDataFrame["Efficacy"].values
generatedPredictionLabel = generatedValidDataFrame["Predicted_Efficacy"].values

generatedR2ScoreValue = r2_score(generatedActualLabel, generatedPredictionLabel)
print(f"Unclipped R² score: {generatedR2ScoreValue:.4f}")

"""PFRED Dataset - GPT-3.5-Turbo"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc
import re
import time
import nest_asyncio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from sklearn.utils import check_array

generatedModelName = "gpt-3.5-turbo"
generatedInputCSV = "/content/PFRED.csv"
generatedOutputCSV = "/content/pfred_gpt35turbo_zeroshot_full.csv"
generatedClient = OpenAI(api_key=generatedAPIKey)
generatedTemperature = 1.1

generatedAccessionMap = {
    "X62295": "Rattus mRNA for vascular type-1 angiotensin II receptor",
    "XM_051583": "Homo sapiens v-raf-1 murine leukemia viral oncogene homolog 1 (RAF1), mRNA",
    "M14758": "Homo sapiens P-glycoprotein (PGY1) mRNA",
    "NM_004996": "Homo sapiens ATP-binding cassette (ABCC1), mRNA",
    "M24283": "Human intercellular adhesion molecule-1 (ICAM-1)",
    "X52479": "Human PKC alpha mRNA",
    "NM_001078": "Homo sapiens VCAM1, transcript variant 1, mRNA",
    "XM_057446": "Homo sapiens SELE mRNA",
    "M30640": "ELAM1 mRNA, complete cds",
    "NM_000877": "Homo sapiens IL1R1 mRNA",
    "M31585": "Mouse ICAM-1 mRNA",
    "BC036531": "Homo sapiens collagen, type I, alpha 1, mRNA",
    "NM_010784": "Mus musculus midkine (Mdk), mRNA",
    "M15077": "Firefly luciferase gene",
    "X03484": "Human raf oncogene mRNA",
    "X14805": "Mus musculus DNA methyltransferase 1",
    "BC005976": "Homo sapiens RhoA mRNA",
    "M10843": "Rabbit beta-globin mRNA",
    "U45880": "XIAP mRNA",
    "AF015950": "Human telomerase reverse transcriptase mRNA",
    "NR_001566": "Human telomerase RNA component (TERC)",
    "M34309": "HER3 mRNA",
    "NM_004507": "HUS1 mRNA",
    "AJ278710": "E. coli 23S rRNA gene",
    "X03363": "Human c-erb-B-2 mRNA",
    "M10988": "Human TNF mRNA",
    "NM_000791": "DHFR mRNA",
    "NM_001168": "BIRC5 mRNA",
    "NM_013642": "Mus musculus Dusp1 mRNA",
    "AF025846": "Co-reporter vector pRL-TK"
}

def generatedSanitizedValue(generatedSequence):
    return str(generatedSequence).strip()

def generatedExtractPredictions(generatedTextSequence):
    generatedMatchesValue = re.findall(r"\b0(?:\.\d+)?|1(?:\.0+)?\b", generatedTextSequence)
    for generatedMatchValue in generatedMatchesValue:
        try:
            generatedValue = float(generatedMatchValue)
            if 0 <= generatedValue <= 1:
                return round(generatedValue, 4)
        except:
            continue
    return np.nan

def generatedPromptValue(generatedRowValue):
    generatedSequence = generatedSanitizedValue(generatedRowValue["DNA Sequence"])
    generatedGeneValue = generatedAccessionMap.get(generatedRowValue["Accession"], "a specific gene")
    return (
        "You are a senior researcher in molecular biology, with deep expertise in antisense oligonucleotide (ASO) design.\n"
        "Given the DNA sequence and its gene target, estimate the inhibition efficacy of gene expression.\n"
        "Consider thermodynamics, off-target effects, hybridization potential, and accessibility.\n"
        "Respond with only a number between 0 and 1 (e.g., 0.13, 0.57, 0.89).\n"
        "Avoid repeating values. Avoid values like 0.75 for every entry. Use biologically diverse reasoning.\n\n"
        f"DNA sequence: {generatedSequence}\n"
        f"Target gene: {generatedGeneValue}\n"
        f"Predicted inhibition efficacy:"
    )

nest_asyncio.apply()
generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["DNA Sequence", "Efficacy"])
generatedDataFrame = generatedDataFrame[generatedDataFrame["Accession"].isin(generatedAccessionMap)].reset_index(drop=True)

generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e in range(len(generatedDataFrame)):
    generatedRowValue = generatedDataFrame.iloc[e]
    generatedPrompt = generatedPromptValue(generatedRowValue)

    try:
        generatedResponseValue = generatedClient.chat.completions.create(
            model=generatedModelName,
            messages=[
                {"role": "system", "content": "You are a molecular biology expert."},
                {"role": "user", "content": generatedPrompt}
            ],
            temperature=generatedTemperature,
            max_tokens=12
        )
        generatedResultValue = generatedResponseValue.choices[0].message.content.strip()
        generatedPredictionsValue = generatedExtractPredictions(generatedResultValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPrompt
        generatedDataFrame.at[e, "Model_Output"] = generatedResultValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedPredictionsValue

        print(f"[Row {e}] {generatedResultValue} → Parsed: {generatedPredictionsValue}")
        gc.collect()
        time.sleep(1)

    except Exception as e:
        print(f"[ERROR] Row {e}: {e}")
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])
generatedValidDataFrame = generatedValidDataFrame[(generatedValidDataFrame["Predicted_Efficacy"] >= 0) & (generatedValidDataFrame["Predicted_Efficacy"] <= 1)]
generatedValidDataFrame.to_csv(generatedOutputCSV, index=False)

print(f"\nTotal valid rows for evaluation: {len(valid)}")

if not generatedValidDataFrame.empty and len(generatedValidDataFrame) > 1:
    generatedActualLabels = check_array(generatedValidDataFrame["Efficacy"], ensure_2d=False)
    generatedPredictionsLabels = check_array(generatedValidDataFrame["Predicted_Efficacy"], ensure_2d=False)

    generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionsLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionsLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nGPT-3.5-Turbo Zero-Shot RMSE (Full): {generatedRMSEValue:.4f}")
    print(f"GPT-3.5-Turbo Zero-Shot R² Score (Full): {abs(generatedR2Score):.4f}")

    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionsLabels, alpha=0.8)
    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("True Efficacy")
    plt.ylabel("Predicted Efficacy")
    plt.title("GPT-3.5-Turbo Zero-Shot (Full): Predicted vs True Efficacy")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
else:
    print("\nNo valid predictions were found or not enough data points for R².")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc
import re
import time
import nest_asyncio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from sklearn.utils import check_array

generatedModelName = "gpt-3.5-turbo"
generatedInputCSV = "/content/PFRED.csv"
generatedOutputCSV = "/content/pfred_gpt35turbo_fewshot_full.csv"
generatedTemperatureValue = 1.1
generatedFewShotExamples = 3
generatedClient = OpenAI(api_key=generatedAPIKey)

generatedAccessionMap = {
    "X62295": "Rattus mRNA for vascular type-1 angiotensin II receptor",
    "XM_051583": "Homo sapiens v-raf-1 murine leukemia viral oncogene homolog 1 (RAF1), mRNA",
    "M14758": "Homo sapiens P-glycoprotein (PGY1) mRNA",
    "NM_004996": "Homo sapiens ATP-binding cassette (ABCC1), mRNA",
    "M24283": "Human intercellular adhesion molecule-1 (ICAM-1)",
    "X52479": "Human PKC alpha mRNA",
    "NM_001078": "Homo sapiens VCAM1, transcript variant 1, mRNA",
    "XM_057446": "Homo sapiens SELE mRNA",
    "M30640": "ELAM1 mRNA, complete cds",
    "NM_000877": "Homo sapiens IL1R1 mRNA",
    "M31585": "Mouse ICAM-1 mRNA",
    "BC036531": "Homo sapiens collagen, type I, alpha 1, mRNA",
    "NM_010784": "Mus musculus midkine (Mdk), mRNA",
    "M15077": "Firefly luciferase gene",
    "X03484": "Human raf oncogene mRNA",
    "X14805": "Mus musculus DNA methyltransferase 1",
    "BC005976": "Homo sapiens RhoA mRNA",
    "M10843": "Rabbit beta-globin mRNA",
    "U45880": "XIAP mRNA",
    "AF015950": "Human telomerase reverse transcriptase mRNA",
    "NR_001566": "Human telomerase RNA component (TERC)",
    "M34309": "HER3 mRNA",
    "NM_004507": "HUS1 mRNA",
    "AJ278710": "E. coli 23S rRNA gene",
    "X03363": "Human c-erb-B-2 mRNA",
    "M10988": "Human TNF mRNA",
    "NM_000791": "DHFR mRNA",
    "NM_001168": "BIRC5 mRNA",
    "NM_013642": "Mus musculus Dusp1 mRNA",
    "AF025846": "Co-reporter vector pRL-TK"
}

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionExtraction(generatedTextValue):
    generatedMatches = re.findall(r"\b0(?:\.\d+)?|1(?:\.0+)?\b", generatedTextValue)
    for generatedValue in generatedMatches:
        try:
            generatedValueFloat = float(generatedValue)
            if 0 <= generatedValueFloat <= 1:
                return round(generatedValueFloat, 4)
        except:
            continue
    return np.nan

def generatedFewShotFunction(generatedRowValue, generatedFewShotExamples):
    generatedSequenceValue = generatedSanitizedSequence(generatedRowValue["DNA Sequence"])
    generatedGeneValue = generatedAccessionMap.get(generatedRowValue["Accession"], "a specific gene")

    generatedPromptValue = (
        "You are a senior researcher in molecular biology, with deep expertise in antisense oligonucleotide (ASO) design.\n"
        "Given the DNA sequence and its gene target, estimate the inhibition efficacy of gene expression.\n"
        "Consider thermodynamics, off-target effects, hybridization potential, and accessibility.\n"
        "Respond with only a number between 0 and 1 (e.g., 0.13, 0.57, 0.89).\n"
        "Avoid repeating values. Avoid values like 0.75 for every entry. Use biologically diverse reasoning.\n\n"
    )

    for generatedExample in generatedExamples:
        generatedSequence = generatedSanitizedSequence(generatedExample["DNA Sequence"])
        generatedExampleGene = generatedAccessionMap.get(generatedExample["Accession"], "a specific gene")
        generatedExampleEfficacy = generatedExample["Efficacy"]
        generatedPromptValue += f"DNA sequence: {generatedSequence}\nTarget gene: {generatedExampleGene}\nPredicted inhibition efficacy: {generatedExampleEfficacy:.2f}\n\n"

    generatedPromptValue += f"DNA sequence: {generatedSequence}\nTarget gene: {generatedGeneValue}\nPredicted inhibition efficacy:"
    return generatedPromptValue

nest_asyncio.apply()
generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["DNA Sequence", "Efficacy"])
generatedDataFrame = generatedDataFrame[generatedDataFrame["Accession"].isin(generatedAccessionMap)].reset_index(drop=True)

generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e in range(len(generatedDataFrame)):
    generatedRowValue = generatedDataFrame.iloc[e]
    pooledCandidatesValue = generatedDataFrame[generatedDataFrame.index != e]
    generatedFewShots = pooledCandidatesValue.sample(n=min(generatedFewShotExamples, len(pooledCandidatesValue)), random_state=i)

    generatedPromptValue = generatedFewShotFunction(generatedRowValue, generatedFewShots.to_dict("records"))

    try:
        generatedResponseValue = generatedClient.chat.completions.create(
            model=generatedModelName,
            messages=[
                {"role": "system", "content": "You are a molecular biology expert."},
                {"role": "user", "content": generatedPromptValue}
            ],
            temperature=generatedTemperatureValue,
            max_tokens=12
        )
        generatedResultValue = generatedResponseValue.choices[0].message.content.strip()
        generatedPredictionValue = generatedPredictionExtraction(generatedResultValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedResultValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedPredictionValue

        print(f"[Row {e}] {generatedResultValue} → Parsed: {generatedPredictionValue}")
        gc.collect()
        time.sleep(1)

    except Exception as e:
        print(f"[ERROR] Row {e}: {e}")
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Efficacy"])
generatedValidDataFrame = generatedValidDataFrame[(generatedValidDataFrame["Predicted_Efficacy"] >= 0) & (generatedValidDataFrame["Predicted_Efficacy"] <= 1)]
generatedValidDataFrame.to_csv(generatedOutputCSV, index=False)

print(f"\nTotal valid rows for evaluation: {len(generatedValidDataFrame)}")

if not generatedValidDataFrame.empty and len(generatedValidDataFrame) > 1:
    generatedActualLabels = check_array(generatedValidDataFrame["Efficacy"], ensure_2d=False)
    generatedPredictionLabels = check_array(generatedValidDataFrame["Predicted_Efficacy"], ensure_2d=False)

    generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidualValue = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotalValue = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Value = 1 - (generatedSSResidualValue / generatedSSTotalValue) if generatedSSTotalValue != 0 else 0.0

    print(f"\nGPT-3.5-Turbo Few-Shot RMSE (Full): {generatedRMSEValue:.4f}")
    print(f"GPT-3.5-Turbo Few-Shot R² Score (Full): {abs(generatedR2Value):.4f}")

    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.8)
    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("True Efficacy")
    plt.ylabel("Predicted Efficacy")
    plt.title("GPT-3.5-Turbo Few-Shot (Full): Predicted vs True Efficacy")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
else:
    print("\nNo valid predictions were found or not enough data points for R².")

"""openASO Dataset - Galactica-6.7B


"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from sklearn.metrics import mean_squared_error

generatedInputCSV = "/content/openASO.csv"
generatedOutputCSV = "/content/openaso1_galactica67b_zeroshot_valid_only.csv"
generatedMetrics = "/content/openaso1_galactica67b_zeroshot_metrics.txt"
generatedPlotPath = "/content/openaso1_galactica67b_zeroshot_plot.png"
generatedInvalidRows = "/content/openaso1_galactica67b_zeroshot_invalid_rows.csv"
generatedModelName = "facebook/galactica-6.7b"
generatedMaximumTokens = 48
generatedOffloadDirectory = "/tmp/offload"

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(text):
    generatedLinesValue = text.strip().splitlines()
    for generatedLineValue in generatedLinesValue:
        generatedMatches = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLineValue)
        for generatedMatch in generatedMatches:
            try:
                generatedValue = float(generatedMatch)
                if 0 <= generatedValue <= 1:
                    return round(generatedValue, 4)
            except:
                continue
    return np.nan

def generatedZeroShotPrompt(generatedRowValue):
    generatedSequence = generatedSanitizedSequence(generatedRowValue["ASOseq"])
    return (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
        f"[START_DNA]{generatedSequence}[END_DNA]\nPredicted inhibition efficacy:"
    )

generatedBNBConfig = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,
    offload_state_dict=True
)

generatedTokenizerValue = AutoTokenizer.from_pretrained(generatedModelName)
generatedTokenizerValue.pad_token = generatedTokenizerValue.eos_token
pad_token_id = generatedTokenizerValue.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="cuda",
    quantization_config=generatedBNBConfig,
    offload_folder=generatedOffloadDirectory
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["ASOseq", "ASOeffective"]).reset_index(drop=True)
generatedDataFrame["ASOeffective"] = generatedDataFrame["ASOeffective"].astype(float).clip(0, 1)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedZeroShotPrompt(generatedRowValue)
        generatedInputsValue = generatedTokenizerValue(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=pad_token_id,
            eos_token_id=generatedTokenizerValue.eos_token_id
        )

        generatedDecodedValue = generatedTokenizerValue.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {e}] Prediction: {generatedParsedValue} → {generatedDecodedValue.strip()}")

        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[e, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "ASOeffective"])
generatedActualLabels = generatedValidDataFrame["ASOeffective"].values
generatedPredictionLabels = generatedValidDataFrame["Predicted_Efficacy"].values

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("Galactica-6.7B Zero-Shot: openASO (1).csv")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)
generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from sklearn.metrics import mean_squared_error

generatedInputCSV = "/content/openASO.csv"
generatedOutputCSV = "/content/openaso1_galactica67b_fewshot_valid_only.csv"
generatedMetricsValue = "/content/openaso1_galactica67b_fewshot_metrics.txt"
generatedPlotPath = "/content/openaso1_galactica67b_fewshot_plot.png"
generatedInvalidRows = "/content/openaso1_galactica67b_fewshot_invalid_rows.csv"
generatedModelName = "facebook/galactica-6.7b"
generatedMaximumTokens = 48
generatedOffloadDirectory = "/tmp/offload"
generatedFewShotCount = 3

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(generatedTextValue):
    generatedLinesValue = generatedTextValue.strip().splitlines()
    for generatedLine in generatedLinesValue:
        generatedMatches = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLine)
        for generatedMatch in generatedMatches:
            try:
                generatedValue = float(generatedMatch)
                if 0 <= generatedValue <= 1:
                    return round(generatedValue, 4)
            except:
                continue
    return None

def generatedFewShotPrompt(generatedTestRow, generatedDataFrame):
    generatedPooledCandidates = generatedDataFrame.drop(index=generatedTestRow.name).dropna(subset=["ASOseq", "ASOeffective"])
    if len(generatedPooledCandidates) < generatedFewShotCount:
        return None
    generatedFewShotSamples = generatedPooledCandidates.sample(n=generatedFewShotCount, random_state=None)

    generatedPromptValue = (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
    )
    for _, generatedSupportRow in generatedFewShotSamples.iterrows():
        generatedSupportSeq = generatedSanitizedSequence(generatedSupportRow["ASOseq"])
        generatedSupportVal = round(float(generatedSupportRow["ASOeffective"]), 4)
        generatedPromptValue += f"[START_DNA]{generatedSupportSeq}[END_DNA]\nPredicted inhibition efficacy: {generatedSupportVal}\n\n"

    generatedTestSequence = generatedSanitizedSequence(generatedTestRow["ASOseq"])
    generatedPromptValue += f"[START_DNA]{generatedTestSequence}[END_DNA]\nPredicted inhibition efficacy:"
    return generatedPromptValue

generatedBNBConfig = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,
    offload_state_dict=True
)

generatedTokenizerValue = AutoTokenizer.from_pretrained(generatedModelName)
generatedTokenizerValue.pad_token = generatedTokenizerValue.eos_token
generatedPadTokenID = generatedTokenizerValue.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="auto",
    torch_dtype=torch.float16,
    quantization_config=generatedBNBConfig,
    offload_folder=generatedOffloadDirectory
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["ASOseq", "ASOeffective"]).reset_index(drop=True)
generatedDataFrame["ASOeffective"] = generatedDataFrame["ASOeffective"].astype(float).clip(0, 1)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for generatedIndex, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedFewShotPrompt(generatedRowValue, generatedDataFrame)
        if not generatedPromptValue:
            continue

        generatedInputsValue = generatedTokenizerValue(
            generatedPromptValue,
            return_tensors="pt",
            truncation=True,
            max_length=2048
        ).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizerValue.eos_token_id
        )

        generatedDecodedText = generatedTokenizerValue.decode(
            generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:],
            skip_special_tokens=True
        )
        generatedParsedValue = generatedPredictionValue(generatedDecodedText)

        if generatedParsedValue is not None:
            generatedDataFrame.at[generatedIndex, "Prompt"] = generatedPromptValue
            generatedDataFrame.at[generatedIndex, "Model_Output"] = generatedDecodedText
            generatedDataFrame.at[generatedIndex, "Predicted_Efficacy"] = generatedParsedValue
            print(f"[Row {generatedIndex}] Prediction: {generatedParsedValue} ← {generatedDecodedText.strip()}")
        else:
            print(f"[Row {generatedIndex}] Skipped due to invalid prediction ← {generatedDecodedText.strip()}")
            continue

        torch.cuda.empty_cache()
        gc.collect()

    except Exception as generatedException:
        print(f"[Row {generatedIndex}] ERROR: {generatedException}")
        continue

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "ASOeffective"])
generatedTrueLabels = generatedValidDataFrame["ASOeffective"].values
generatedPredictedLabels = generatedValidDataFrame["Predicted_Efficacy"].values

generatedRMSEValue = np.sqrt(np.mean((generatedTrueLabels - generatedPredictedLabels) ** 2))
generatedSSResidual = np.sum((generatedTrueLabels - generatedPredictedLabels) ** 2)
generatedSSTotal = np.sum((generatedTrueLabels - np.mean(generatedTrueLabels)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetricsValue, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedTrueLabels, generatedPredictedLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("Galactica-6.7B Few-Shot: openASO.csv")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)
generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

"""openASO Dataset - LLaMA2-7B


"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from huggingface_hub import login
from sklearn.metrics import mean_squared_error, r2_score

generatedInputCSV = "/content/openASO.csv"
generatedOutputCSV = "/content/openaso1_llama27b_zeroshot_valid_only.csv"
generatedMetrics = "/content/openaso1_llama27b_zeroshot_metrics.txt"
generatedPlotPath = "/content/openaso1_llama27b_zeroshot_plot.png"
generatedInvalidRows = "/content/openaso1_llama27b_zeroshot_invalid_rows.csv"
generatedModelName = "meta-llama/Llama-2-7b-hf"
generatedMaximumTokens = 48

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(generatedTextSequence):
    generatedLines = generatedTextSequence.strip().splitlines()
    for generatedLineValue in generatedLines:
        generatedMatchesValue = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLineValue)
        for generatedMatchValue in generatedMatchesValue:
            try:
                generatedValue = float(generatedMatchValue)
                if 0 < generatedValue < 1:
                    return round(generatedValue, 4)
            except:
                continue
    return None

def generatedZeroShotPrompt(generatedRowValue):
    generatedSequence = generatedSanitizedSequence(generatedRowValue["ASOseq"])
    return (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
        f"[DNA_START]{generatedSequence}[DNA_END]\nPredicted inhibition efficacy:"
    )

generatedBNBConfig = BitsAndBytesConfig(load_in_8bit=True)
generatedTokenizerValue = AutoTokenizer.from_pretrained(generatedModelName, use_auth_token=True)
generatedTokenizerValue.pad_token = generatedTokenizerValue.eos_token
generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="auto",
    torch_dtype=torch.float16,
    quantization_config=generatedBNBConfig,
    use_auth_token=True
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["ASOseq", "ASOeffective"]).reset_index(drop=True)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

generatedInvalidRows = []

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedZeroShotPrompt(generatedRowValue)
        generatedInputsValue = generatedTokenizerValue(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedTokenizerValue.pad_token_id,
            eos_token_id=generatedTokenizerValue.eos_token_id
        )

        generatedDecodedValue = generatedTokenizerValue.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        if generatedParsedValue is not None and isinstance(generatedParsedValue, float) and 0 < generatedParsedValue < 1:
            generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
            generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
            generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue
            print(f"[Row {e}] Prediction: {generatedParsedValue} ← {generatedDecodedValue.strip()}")
        else:
            print(f"[Row {e}] Skipped: Invalid prediction ← {generatedDecodedValue.strip()}")
            generatedInvalidRows.append(generatedRowValue)
            continue

        gc.collect()
        torch.cuda.empty_cache()

    except Exception as e:
        print(f"[Row {i}] ERROR: {e}")
        generatedInvalidRows.append(generatedRowValue)
        gc.collect()
        torch.cuda.empty_cache()
        continue

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "ASOeffective"])
generatedActualLabels = generatedValidDataFrame["ASOeffective"].values
generatedPredictionsLabels = generatedValidDataFrame["Predicted_Efficacy"].values
generatedRMSEValue = np.sqrt(mean_squared_error(generatedActualLabels, generatedPredictionsLabels))
generatedR2Score = r2_score(generatedActualLabels, generatedPredictionsLabels)

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Score:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Score:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionsLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("LLaMA2-7B Zero-Shot: openASO (1).csv")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)

generatedInvalidDataFrame = pd.DataFrame(generatedInvalidRows)
if not generatedInvalidDataFrame.empty:
    generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
    print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")
else:
    print("\nNo invalid entries were skipped.")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch, random
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from huggingface_hub import login
from sklearn.metrics import mean_squared_error, r2_score

generatedInputCSV = "/content/openASO.csv"
generatedOutputCSV = "/content/openaso1_llama27b_fewshot_valid_only.csv"
generatedMetrics = "/content/openaso1_llama27b_fewshot_metrics.txt"
generatedPlotPath = "/content/openaso1_llama27b_fewshot_plot.png"
generatedInvalidRows = "/content/openaso1_llama27b_fewshot_invalid_rows.csv"
generatedModelName = "meta-llama/Llama-2-7b-hf"
generatedMaximumTokens = 48
generatedFewShotExamples = 3

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(generatedTextSequence):
    generatedLinesValue = generatedTextSequence.strip().splitlines()
    for generatedLineValue in generatedLinesValue:
        generatedMatchesValue = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLineValue)
        for generatedMatchValue in generatedMatchesValue:
            try:
                generatedValue = float(generatedMatchValue)
                if 0 < generatedValue < 1:
                    return round(generatedValue, 4)
            except:
                continue
    return None

def generatedFewShotPrompt(generatedTestRow, generatedFewShotRows):
    generatedPromptValue = (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Below are a few examples with known efficacy values.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
    )
    for _, generatedRowValue in generatedFewShotRows.iterrows():
        generatedSequence = generatedSanitizedSequence(generatedRowValue["ASOseq"])
        generatedValue = round(float(generatedRowValue["ASOeffective"]), 4)
        generatedPromptValue += f"[DNA_START]{generatedSequence}[DNA_END]\nPredicted inhibition efficacy: {generatedValue}\n\n"

    generatedTestSequence = generatedSanitizedSequence(generatedTestRow["ASOseq"])
    generatedPromptValue += f"[DNA_START]{generatedTestSequence}[DNA_END]\nPredicted inhibition efficacy:"
    return generatedPromptValue

generatedBNBConfig = BitsAndBytesConfig(load_in_8bit=True)
generatedTokenizerValue = AutoTokenizer.from_pretrained(generatedModelName, use_auth_token=True)
generatedTokenizerValue.pad_token = generatedTokenizerValue.eos_token
generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="auto",
    torch_dtype=torch.float16,
    quantization_config=generatedBNBConfig,
    use_auth_token=True
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["ASOseq", "ASOeffective"]).reset_index(drop=True)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

generatedInvalidRows = []

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPoolValue = generatedDataFrame.drop(index=i).drop_duplicates(subset=["ASOseq"]).dropna(subset=["ASOeffective"])
        generatedFewShot = generatedPoolValue.sample(n=min(generatedFewShotExamples, len(generatedPoolValue)), random_state=None)
        generatedPromptValue = generatedFewShotPrompt(generatedRowValue, generatedFewShot)

        generatedInputsValue = generatedTokenizerValue(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedTokenizerValue.pad_token_id,
            eos_token_id=generatedTokenizerValue.eos_token_id
        )

        generatedDecodedValue = generatedTokenizerValue.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        if generatedParsedValue is not None and isinstance(generatedParsedValue, float) and 0 < generatedParsedValue < 1:
            generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
            generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
            generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue
            print(f"[Row {e}] Prediction: {generatedParsedValue} ← {generatedDecodedValue.strip()}")
        else:
            print(f"[Row {e}] Skipped: Invalid prediction ← {decoded.strip()}")
            generatedInvalidRows.append(generatedRowValue)
            continue

        gc.collect()
        torch.cuda.empty_cache()

    except Exception as e:
        print(f"[Row {i}] ERROR: {e}")
        generatedInvalidRows.append(generatedRowValue)
        gc.collect()
        torch.cuda.empty_cache()
        continue

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "ASOeffective"])
generatedActualLabels = generatedValidDataFrame["ASOeffective"].values
generatedPredictionLabels = generatedValidDataFrame["Predicted_Efficacy"].values
generatedRMSEValue = np.sqrt(mean_squared_error(generatedActualLabels, generatedPredictionLabels))
generatedR2Score = r2_score(generatedActualLabels, generatedPredictionLabels)

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Score:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Score:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Efficacy")
plt.ylabel("Predicted Efficacy")
plt.title("LLaMA2-7B Few-Shot (Random): openASO (1).csv")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)

generatedInvalidDataFrame = pd.DataFrame(generatedInvalidRows)
if not generatedInvalidDataFrame.empty:
    generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
    print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")
else:
    print("\nNo invalid entries were skipped.")

"""openASO Dataset - GPT-3.5-Turbo"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import gc
import re
import time
import nest_asyncio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from sklearn.utils import check_array

generatedModelName = "gpt-3.5-turbo"
generatedInputCSV = "/content/openASO.csv"
generatedOutputCSV = "/content/openaso1_gpt35turbo_zeroshot.csv"
generatedPlotPath = "/content/openaso1_gpt35turbo_plot_zeroshot.png"
generatedTemperatureValue = 1.0

generatedClientValue = OpenAI(api_key=generatedAPIKey)

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedExtractionValue(generatedTextSequence):
    generatedMatches = re.findall(r"\b0(?:\.\d+)?|1(?:\.0+)?\b", generatedTextSequence)
    for generatedMatchValue in generatedMatches:
        try:
            generatedValue = float(generatedMatchValue)
            if 0 <= generatedValue <= 1:
                return round(generatedValue, 4)
        except:
            continue
    return np.nan

def generatedFewShotPrompt(generatedRowValue):
    generatedSequence = generatedSanitizedSequence(generatedRowValue["ASOseq"])
    return (
        "You are a senior researcher in molecular biology, with deep expertise in antisense oligonucleotide (ASO) design.\n"
        "Given the DNA sequence, estimate the inhibition efficacy of gene expression.\n"
        "Respond with only a number between 0 and 1 (e.g., 0.13, 0.57, 0.89).\n"
        "Do not repeat or copy values from other predictions.\n\n"
        f"DNA sequence: {generatedSequence}\n"
        f"Predicted inhibition efficacy:"
    )

nest_asyncio.apply()
generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["ASOseq", "ASOeffective"]).reset_index(drop=True)

generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e in range(len(generatedDataFrame)):
    generatedRowValue = generatedDataFrame.iloc[i]
    generatedPromptValue = generatedFewShotPrompt(generatedRowValue)

    try:
        generatedResponseValue = generatedClientValue.chat.completions.create(
            model=generatedModelName,
            messages=[
                {"role": "system", "content": "You are a molecular biology expert."},
                {"role": "user", "content": prompt}
            ],
            temperature=generatedTemperatureValue,
            max_tokens=12
        )
        generatedResult = generatedResponseValue.choices[0].message.content.strip()
        generatedPrediction = generatedExtractionValue(generatedResult)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedResult
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedPrediction

        print(f"[Row {e}] {generatedResult} → Parsed: {generatedPrediction}")
        gc.collect()
        time.sleep(1)

    except Exception as e:
        print(f"[ERROR] Row {e}: {e}")
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "ASOeffective"])
generatedValidDataFrame = generatedValidDataFrame[(generatedValidDataFrame["Predicted_Efficacy"] >= 0) & (generatedValidDataFrame["Predicted_Efficacy"] <= 1)]
generatedValidDataFrame.to_csv(generatedOutputCSV, index=False)

print(f"\nTotal valid rows for evaluation: {len(generatedValidDataFrame)}")

if not generatedValidDataFrame.empty and len(generatedValidDataFrame) > 1:
    generatedActualLabels = check_array(generatedValidDataFrame["ASOeffective"].astype(float), ensure_2d=False)
    generatedPredictionLabels = check_array(generatedValidDataFrame["Predicted_Efficacy"].astype(float), ensure_2d=False)

    generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nGPT-3.5-Turbo Zero-Shot RMSE (openASO1): {generatedRMSEValue:.4f}")
    print(f"GPT-3.5-Turbo Zero-Shot R² Score (openASO1): {generatedR2Score:.4f}")

    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.8)
    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("True ASOeffective")
    plt.ylabel("Predicted ASOeffective")
    plt.title("GPT-3.5-Turbo Zero-Shot (openASO1): Predicted vs True Efficacy")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(generatedPlotPath)
    plt.show()
else:
    print("\nNo valid predictions were found or not enough data points for R².")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import gc
import re
import time
import nest_asyncio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from sklearn.utils import check_array

generatedModelName = "gpt-3.5-turbo"
generatedInputCSV = "/content/openASO.csv"
generatedOutputCSV = "/content/openaso1_gpt35turbo_fewshot.csv"
generatedPlotPath = "/content/openaso1_gpt35turbo_fewshot_plot.png"
generatedTemperatureValue = 1.0
generatedExamples = 3

generatedClientValue = OpenAI(api_key=generatedAPIKey)

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedExtractionValue(generatedTextSequence):
    generatedMatches = re.findall(r"\b0(?:\.\d+)?|1(?:\.0+)?\b", generatedTextSequence)
    for generatedMatchValue in generatedMatches:
        try:
            generatedValue = float(generatedMatchValue)
            if 0 <= generatedValue <= 1:
                return round(generatedValue, 4)
        except:
            continue
    return np.nan

def generatedFewShotPrompt(generatedTestRow, generatedFewShotRows):
    generatedPromptValue = (
        "You are a senior researcher in molecular biology, with deep expertise in antisense oligonucleotide (ASO) design.\n"
        "Given the DNA sequence, estimate the inhibition efficacy of gene expression.\n"
        "Respond with only a number between 0 and 1 (e.g., 0.13, 0.57, 0.89).\n\n"
    )
    for _, generatedRowValue in generatedFewShotRows.iterrows():
        generatedSequence = generatedSanitizedSequence(generatedRowValue["ASOseq"])
        generatedEfficacyValue = round(float(generatedRowValue["ASOeffective"]), 4)
        generatedPromptValue += f"DNA sequence: {generatedSequence}\nPredicted inhibition efficacy: {generatedEfficacyValue}\n\n"

    generatedTestSequence = generatedSanitizedSequence(generatedTestRow["ASOseq"])
    generatedPromptValue += f"DNA sequence: {generatedTestSequence}\nPredicted inhibition efficacy:"
    return generatedPromptValue

nest_asyncio.apply()
generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["ASOseq", "ASOeffective"]).reset_index(drop=True)

generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e in range(len(generatedDataFrame)):
    generatedTestRow = generatedDataFrame.iloc[e]
    generatedFewShotRows = generatedDataFrame.drop(index=i).sample(generatedExamples, random_state=None)
    generatedPromptValue = generatedFewShotPrompt(generatedTestRow, generatedFewShotRows)

    try:
        generatedResponseValue = generatedClientValue.chat.completions.create(
            model=generatedModelName,
            messages=[
                {"role": "system", "content": "You are a molecular biology expert."},
                {"role": "user", "content": generatedPromptValue}
            ],
            temperature=generatedTemperatureValue,
            max_tokens=12
        )
        generatedResultValue = generatedResponseValue.choices[0].message.content.strip()
        generatedPredictionValue = generatedExtractionValue(generatedResultValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedResultValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedPredictionValue

        print(f"[Row {e}] {generatedResultValue} → Parsed: {generatedPredictionValue}")
        gc.collect()
        time.sleep(1)

    except Exception as e:
        print(f"[ERROR] Row {e}: {e}")
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "ASOeffective"])
generatedValidDataFrame = generatedValidDataFrame[(generatedValidDataFrame["Predicted_Efficacy"] >= 0) & (generatedValidDataFrame["Predicted_Efficacy"] <= 1)]
generatedValidDataFrame.to_csv(generatedOutputCSV, index=False)

print(f"\nTotal valid rows for evaluation: {len(valid)}")

if not generatedValidDataFrame.empty and len(generatedValidDataFrame) > 1:
    generatedActualLabels = check_array(generatedValidDataFrame["ASOeffective"].astype(float), ensure_2d=False)
    generatedPredictionLabels = check_array(generatedValidDataFrame["Predicted_Efficacy"].astype(float), ensure_2d=False)

    generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nGPT-3.5-Turbo Few-Shot RMSE (openASO1): {generatedRMSEValue:.4f}")
    print(f"GPT-3.5-Turbo Few-Shot R² Score (openASO1): {generatedR2Score:.4f}")

    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.8)
    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("True ASOeffective")
    plt.ylabel("Predicted ASOeffective")
    plt.title("GPT-3.5-Turbo Few-Shot (openASO1): Predicted vs True Efficacy")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(generatedPlotPath)
    plt.show()
else:
    print("\nNo valid predictions were found or not enough data points for R².")

"""ASOptimizer Dataset - Galactica-6.7B"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from sklearn.metrics import mean_squared_error

generatedInputCSV = "/content/ASOptimizer.csv"
generatedOutputCSV = "/content/asoptimizer2_galactica67b_zeroshot_valid_only.csv"
generatedMetrics = "/content/asoptimizer2_galactica67b_zeroshot_metrics.txt"
generatedPlotPath = "/content/asoptimizer2_galactica67b_zeroshot_plot.png"
generatedInvalidRows = "/content/asoptimizer2_galactica67b_zeroshot_invalid_rows.csv"
generatedModelName = "facebook/galactica-6.7b"
generatedMaximumTokens = 48
generatedOffloadDirectory = "/tmp/offload"

def generatedSanitizedSequence(generatedSequenceValue):
    return str(generatedSequenceValue).strip()

def generatedPredictionValue(generatedTextValue):
    generatedCleanedText = re.split(r"\b(?:Title|ABSTRACT|Figure|Introduction)\b", generatedTextValue.strip())[0]
    generatedCleanedText = re.sub(r"[^\d\.\s]", " ", generatedCleanedText)  # Remove non-numeric characters

    generatedMatchesValue = re.findall(r"\b0(?:\.\d{1,5})?\b|\b1(?:\.0+)?\b", generatedCleanedText)
    for generatedMatchValue in generatedMatchesValue:
        try:
            generatedValue = float(generatedMatchValue)
            if 0 <= generatedValue <= 1:
                return round(generatedValue, 4)
        except:
            continue
    return np.nan

def generatedZeroShotPrompt(generatedRowValue):
    generatedSequenceValue = generatedSanitizedSequence(generatedRowValue["Sequence"])
    return (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
        f"[START_DNA]{generatedSequenceValue}[END_DNA]\nPredicted inhibition efficacy:"
    )

generatedBNBConfig = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,
    offload_state_dict=True
)

generatedTokenizerValue = AutoTokenizer.from_pretrained(generatedModelName)
generatedTokenizerValue.pad_token = generatedTokenizerValue.eos_token
generatedPadTokenID = generatedTokenizerValue.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="cuda",
    quantization_config=generatedBNBConfig,
    offload_folder=generatedOffloadDirectory
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["Sequence", "Inhibition(%)"]).reset_index(drop=True)
generatedDataFrame["Inhibition(%)"] = generatedDataFrame["Inhibition(%)"].astype(float).clip(0, 100)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedZeroShotPrompt(generatedRowValue)
        generatedInputsValue = generatedTokenizerValue(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizerValue.eos_token_id
        )

        generatedDecodedValue = tokenizer.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedDecodedValue = re.split(r"\b(?:Title|ABSTRACT|Figure|Introduction)\b", generatedDecodedValue.strip())[0].strip()
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {e}] Prediction: {generatedParsedValue} → {generatedDecodedValue}")

        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[e, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Inhibition(%)"])
generatedActualLabels = generatedValidDataFrame["Inhibition(%)"].values / 100
generatedPredictionLabels = generatedValidDataFrame["Predicted_Efficacy"].values

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Score:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Score:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Inhibition (normalized)")
plt.ylabel("Predicted Efficacy")
plt.title("Galactica-6.7B Zero-Shot: ASOptimizer.csv")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)
generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from sklearn.metrics import mean_squared_error

generatedInputCSV = "/content/ASOptimizer.csv"
generatedOutputCSV = "/content/asoptimizer2_galactica67b_fewshot_valid_only.csv"
generatedMetrics = "/content/asoptimizer2_galactica67b_fewshot_metrics.txt"
generatedPlotPath = "/content/asoptimizer2_galactica67b_fewshot_plot.png"
generatedInvalidRows = "/content/asoptimizer2_galactica67b_fewshot_invalid_rows.csv"
generatedModelName = "facebook/galactica-6.7b"
generatedMaximumTokens = 48
generatedOffloadDirectory = "/tmp/offload"
fewShotExamples = 3

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedPredictionValue(generatedText):
    generatedLinesValue = generatedText.strip().splitlines()
    for generatedLineValue in generatedLinesValue:
        generatedMatchesValue = re.findall(r"\b0(?:\.\d{1,4})?\b|\b1(?:\.0+)?\b", generatedLineValue)
        for generatedMatchValue in generatedMatchesValue:
            try:
                generatedValue = float(generatedMatchValue)
                if 0 <= generatedValue <= 1:
                    return round(generatedValue, 4)
            except:
                continue
    return np.nan

def generatedFewShotPrompt(generatedTestRow, generatedDataFrame):
    generatedPooledCandidates = generatedDataFrame.drop(index=generatedTestRow.name)
    if len(generatedPooledCandidates) < fewShotExamples:
        return None
    generatedFewShots = generatedPooledCandidates.sample(n=fewShotExamples, random_state=None)
    generatedPromptValue = (
        "You are a molecular biology expert predicting inhibition efficacy of antisense DNA sequences.\n"
        "Only respond with a numeric score between 0 and 1 (e.g., 0.42). Do not provide explanation or units.\n\n"
    )
    for _, generatedRowValue in generatedFewShots.iterrows():
        generatedSequenceValue = generatedSanitizedSequence(generatedRowValue["Sequence"])
        generatedEfficacyValue = round(float(generatedRowValue["Inhibition(%)"]) / 100, 4)
        generatedPromptValue += f"[START_DNA]{generatedSequenceValue}[END_DNA]\nPredicted inhibition efficacy: {generatedEfficacyValue}\n\n"
    generatedTestSequence = generatedSanitizedSequence(generatedTestRow["Sequence"])
    generatedPromptValue += f"[START_DNA]{generatedTestSequence}[END_DNA]\nPredicted inhibition efficacy:"
    return generatedPromptValue

generatedBNBConfig = BitsAndBytesConfig(
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,
    offload_state_dict=True
)

generatedTokenizerValue = AutoTokenizer.from_pretrained(generatedModelName)
generatedTokenizerValue.pad_token = generatedTokenizerValue.eos_token
generatedPadTokenID = generatedTokenizerValue.pad_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    device_map="cuda",
    quantization_config=generatedBNBConfig,
    offload_folder=generatedOffloadDirectory
)
generatedModelValue.eval()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["Sequence", "Inhibition(%)"]).reset_index(drop=True)
generatedDataFrame["Inhibition(%)"] = generatedDataFrame["Inhibition(%)"].astype(float).clip(0, 100)
generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e, generatedRowValue in generatedDataFrame.iterrows():
    try:
        generatedPromptValue = generatedFewShotPrompt(generatedRowValue, generatedDataFrame)
        if not generatedPromptValue:
            continue

        generatedInputsValue = generatedTokenizerValue(generatedPromptValue, return_tensors="pt", truncation=True, max_length=2048).to("cuda")
        generatedInputsValue.pop("token_type_ids", None)

        generatedOutputsValue = generatedModelValue.generate(
            **generatedInputsValue,
            max_new_tokens=generatedMaximumTokens,
            do_sample=True,
            temperature=0.7,
            top_p=0.85,
            top_k=20,
            repetition_penalty=1.1,
            pad_token_id=generatedPadTokenID,
            eos_token_id=generatedTokenizerValue.eos_token_id
        )

        generatedDecodedValue = generatedTokenizerValue.decode(generatedOutputsValue[0][generatedInputsValue["input_ids"].shape[1]:], skip_special_tokens=True)
        generatedParsedValue = generatedPredictionValue(generatedDecodedValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedDecodedValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedParsedValue

        print(f"[Row {e}] Prediction: {generatedParsedValue} → {generatedDecodedValue.strip()}")

        torch.cuda.empty_cache()
        gc.collect()

    except Exception as e:
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {e}"
        generatedDataFrame.at[e, "Predicted_Efficacy"] = np.nan
        torch.cuda.empty_cache()
        gc.collect()

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Inhibition(%)"])
generatedActualLabel = generatedValidDataFrame["Inhibition(%)"].values / 100  # Normalize
generatedPredictionLabel = generatedValidDataFrame["Predicted_Efficacy"].values

generatedRMSEValue = np.sqrt(np.mean((generatedActualLabel - generatedPredictionLabel) ** 2))
generatedSSResidual = np.sum((generatedActualLabel - generatedPredictionLabel) ** 2)
generatedSSTotal = np.sum((generatedActualLabel - np.mean(generatedActualLabel)) ** 2)
generatedR2Value = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

print(f"\nEvaluation Metrics on {len(generatedValidDataFrame)} valid entries:")
print(f"  RMSE: {generatedRMSEValue:.4f}")
print(f"  R²:   {generatedR2Value:.4f}")

with open(generatedMetrics, "w") as f:
    f.write(f"RMSE: {generatedRMSEValue:.4f}\nR2: {generatedR2Value:.4f}\n")

plt.figure(figsize=(6, 6))
plt.scatter(generatedActualLabel, generatedPredictionLabel, alpha=0.7)
plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
plt.xlabel("True Inhibition (normalized)")
plt.ylabel("Predicted Efficacy")
plt.title("Galactica-6.7B Few-Shot: ASOptimizer (2).csv")
plt.grid(True)
plt.tight_layout()
plt.savefig(generatedPlotPath)
plt.show()

generatedDataFrame.to_csv(generatedOutputCSV, index=False)
generatedInvalidDataFrame = generatedDataFrame[generatedDataFrame["Predicted_Efficacy"].isna()]
generatedInvalidDataFrame.to_csv(generatedInvalidRows, index=False)
print(f"\nSkipped {len(generatedInvalidDataFrame)} entries due to invalid predictions → saved to: {generatedInvalidRows}")

"""ASOptimizer Dataset - Llama2-7b-hf"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc, re, time, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from huggingface_hub import login

generatedInputCSV = "/content/ASOptimizer.csv"
generatedOutputCSV = "/content/asoptimizer2_llama2_7b_zeroshot.csv"
generatedPlotPath = "/content/asoptimizer2_llama2_7b_zeroshot_plot.png"
generatedModelName = "meta-llama/Llama-2-7b-hf"
generatedNewTokens = 48

login(token=generatedHuggingFaceToken)

def generatedSanitizedSequence(generatedSequence: str) -> str:
    if not isinstance(generatedSequence, str) or len(generatedSequence.strip()) < 5:
        return ""
    generatedSequence = re.sub(r"[\u200B-\u200D\uFEFF]", "", generatedSequence.strip())
    generatedSequence = re.sub(r"\[DNA_START\]|\[DNA_END\]", "", generatedSequence)
    return generatedSequence

def generatedOutput(generatedOutputValue: str):
    generatedOutputValue = generatedOutputValue.strip()
    match = re.search(r"(?<!\d)(0?\.\d{1,4}|1\.0{0,4})(?!\d)", generatedOutputValue)
    if match:
        try:
            return round(float(match.group(1)), 4)
        except:
            return np.nan
    return np.nan

def generatedPromptZeroShot(generatedRowValue):
    generatedTestSequence = generatedSanitizedSequence(generatedRowValue["Sequence"])
    return (
        "You are an expert in antisense oligonucleotide (ASO) design.\n"
        "Given a DNA sequence, estimate its gene inhibition efficacy.\n"
        "Return only a numeric score between 0 and 1.\n\n"
        f"DNA sequence: [DNA_START]{generatedTestSequence}[DNA_END]\nPredicted inhibition efficacy:"
    )

def plot_results(generatedActualLabels, generatedPredictionLabels, generatedPath):
    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.5)
    plt.plot([0, 1], [0, 1], "--", color="gray")
    plt.xlabel("True Inhibition(%)")
    plt.ylabel("Predicted Inhibition")
    plt.title("Zero-Shot: Predicted vs True Inhibition")
    plt.grid(True)
    plt.savefig(generatedPath)
    plt.close()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["Sequence", "Inhibition(%)"]).reset_index(drop=True)
generatedDataFrame["Inhibition(%)"] = generatedDataFrame["Inhibition(%)"].astype(float).clip(0, 100) / 100

generatedBNBConfig = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=torch.float16,
    llm_int8_enable_fp32_cpu_offload=True
)

generatedTokenizerValue = AutoTokenizer.from_pretrained(
    generatedModelName,
    token=generatedHuggingFaceToken,
    padding_side="left",
    use_fast=False,
    trust_remote_code=True
)
if generatedTokenizerValue.pad_token is None:
    generatedTokenizerValue.add_special_tokens({'pad_token': generatedTokenizerValue.eos_token})
generatedTokenizerValue.pad_token_id = generatedTokenizerValue.eos_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    token=generatedHuggingFaceToken,
    device_map="cuda",
    torch_dtype=torch.float16,
    quantization_config=generatedBNBConfig,
    trust_remote_code=True
)
generatedModelValue.resize_token_embeddings(len(generatedTokenizerValue))
generatedModelValue.eval()
generatedDeviceValue = next(generatedModelValue.parameters()).device

generatedResultsValue = []
generatedStartTime = time.time()

for idx, generatedRowValue in tqdm(generatedDataFrame.iterrows(), total=len(generatedDataFrame)):
    try:
        generatedPromptValue = generatedPromptZeroShot(generatedRowValue)

        generatedInputsValue = generatedTokenizerValue(
            generatedPromptValue,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=2048
        )
        generatedInputsValue = {k: v.to(generatedDeviceValue) for k, v in generatedInputsValue.items() if k != "token_type_ids"}

        with torch.no_grad():
            generatedOutputsValue = generatedModelValue.generate(
                **generatedInputsValue,
                max_new_tokens=generatedNewTokens,
                do_sample=True,
                temperature=0.75,
                top_p=0.7,
                use_cache=True,
                eos_token_id=generatedTokenizerValue.eos_token_id,
                pad_token_id=generatedTokenizerValue.pad_token_id
            )

        generatedDecodedValue = generatedTokenizerValue.decode(generatedOutputsValue[0], skip_special_tokens=True)
        generatedCleanDecodedValue = generatedDecodedValue.replace(generatedPromptValue, "").strip()
        generatedPrediction = generatedOutput(generatedCleanDecodedValue)

        if not np.isnan(generatedPrediction) and 0 <= generatedPrediction <= 1:
            generatedRowDictionary = generatedRowValue.to_dict()
            generatedRowDictionary["Raw_Output"] = generatedCleanDecodedValue
            generatedRowDictionary["Predicted_Inhibition"] = float(generatedPrediction)
            generatedResultsValue.append(generatedRowDictionary)

    except Exception as e:
        print(f"[ERROR] Row {idx}: {repr(e)}")

    gc.collect()
    torch.cuda.empty_cache()

generatedEndTime = time.time()
print(f"\nTotal inference time: {generatedEndTime - generatedStartTime:.2f} seconds")

generatedFinalDataFrame = pd.DataFrame(generatedResultsValue)
generatedFinalDataFrame.to_csv(generatedOutputCSV, index=False)

if 'Predicted_Inhibition' in generatedFinalDataFrame.columns and 'Inhibition(%)' in generatedFinalDataFrame.columns:
    generatedActualLabels = generatedFinalDataFrame["Inhibition(%)"].astype(float).values
    generatedPredictionLabels = generatedFinalDataFrame["Predicted_Inhibition"].astype(float).values

    generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nFinal RMSE: {generatedRMSEValue:.4f}")
    print(f"Final R² Score: {generatedR2Score:.4f}")
    plot_results(generatedActualLabels, generatedPredictionLabels, generatedPlotPath)
else:
    print("\nEvaluation skipped — no valid predictions.")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

!pip install -qU transformers huggingface_hub bitsandbytes matplotlib tqdm pandas scikit-learn

import gc, re, time, torch
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from huggingface_hub import login
from sklearn.utils import check_array

generatedInputCSV = "/content/ASOptimizer.csv"
generatedOutputCSV = "/content/asoptimizer2_llama2_7b_fewshot.csv"
generatedPlotPath = "/content/asoptimizer2_llama2_7b_fewshot_plot.png"
generatedModelName = "meta-llama/Llama-2-7b-hf"
generatedNewTokens = 48
fewShotExamples = 3

login(token=generatedHuggingFaceToken)

def generatedSanitizedSequence(generatedSequence: str) -> str:
    if not isinstance(generatedSequence, str) or len(generatedSequence.strip()) < 5:
        return ""
    generatedSequence = re.sub(r"[\u200B-\u200D\uFEFF]", "", generatedSequence.strip())
    generatedSequence = re.sub(r"\[DNA_START\]|\[DNA_END\]", "", generatedSequence)
    return generatedSequence

def generatedOutput(generatedOutputValue: str):
    generatedOutputValue = generatedOutputValue.strip()
    match = re.search(r"(?<!\d)(0?\.\d{1,4}|1\.0{0,4})(?!\d)", generatedOutputValue)
    if match:
        try:
            return round(float(match.group(1)), 4)
        except:
            return np.nan
    return np.nan

def generatedPromptFewShot(generatedRowValue, generatedFewShotRows):
    generatedFewShots = []
    for _, r in generatedFewShotRows.iterrows():
        generatedSequence = generatedSanitizedSequence(r["Sequence"])
        generatedEfficacy = round(float(r["Inhibition(%)"]) / 100, 4)
        generatedFewShots.append(f"DNA sequence: [DNA_START]{generatedSequence}[DNA_END]\nPredicted inhibition efficacy: {generatedEfficacy}")
    generatedTestSequence = generatedSanitizedSequence(generatedRowValue["Sequence"])
    generatedTestBlock = f"DNA sequence: [DNA_START]{generatedTestSequence}[DNA_END]\nPredicted inhibition efficacy:"
    return (
        "You are an expert in antisense oligonucleotide (ASO) design.\n"
        "Given a DNA sequence and its inhibition efficacy, predict the efficacy for a new sequence.\n"
        "Return only a numeric score between 0 and 1.\n\n"
        + "\n\n".join(generatedFewShots)
        + "\n\n"
        + generatedTestBlock
    )

def plot_results(generatedActualLabels, generatedPredictionLabels, generatedPath):
    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.5)
    plt.plot([0, 1], [0, 1], "--", color="gray")
    plt.xlabel("True Inhibition")
    plt.ylabel("Predicted Inhibition")
    plt.title("Few-Shot: Predicted vs True Inhibition")
    plt.grid(True)
    plt.savefig(generatedPath)
    plt.close()

generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["Sequence", "Inhibition(%)"]).reset_index(drop=True)

generatedBNBConfig = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_compute_dtype=torch.float16,
    llm_int8_enable_fp32_cpu_offload=True
)

generatedTokenizerValue = AutoTokenizer.from_pretrained(
    generatedModelName,
    token=generatedHuggingFaceToken,
    padding_side="left",
    use_fast=False,
    trust_remote_code=True
)
if generatedTokenizerValue.pad_token is None:
    generatedTokenizerValue.add_special_tokens({'pad_token': generatedTokenizerValue.eos_token})
generatedTokenizerValue.pad_token_id = generatedTokenizerValue.eos_token_id

generatedModelValue = AutoModelForCausalLM.from_pretrained(
    generatedModelName,
    token=generatedHuggingFaceToken,
    device_map="cuda",
    torch_dtype=torch.float16,
    quantization_config=generatedBNBConfig,
    trust_remote_code=True
)
generatedModelValue.resize_token_embeddings(len(generatedTokenizerValue))
generatedModelValue.eval()
generatedDeviceValue = next(generatedModelValue.parameters()).device

generatedResultsValue = []
generatedStartTime = time.time()

for idx, generatedRowValue in tqdm(generatedDataFrame.iterrows(), total=len(generatedDataFrame)):
    try:
        generatedFewShotRows = generatedDataFrame.drop(index=idx).sample(fewShotExamples, random_state=None)
        generatedPromptValue = generatedPromptFewShot(generatedRowValue, generatedFewShotRows)

        generatedInputsValue = generatedTokenizerValue(
            generatedPromptValue,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=2048
        )
        generatedInputsValue = {k: v.to(generatedDeviceValue) for k, v in generatedInputsValue.items() if k != "token_type_ids"}

        with torch.no_grad():
            generatedOutputsValue = generatedModelValue.generate(
                **generatedInputsValue,
                max_new_tokens=generatedNewTokens,
                do_sample=True,
                temperature=0.75,
                top_p=0.7,
                use_cache=True,
                eos_token_id=generatedTokenizerValue.eos_token_id,
                pad_token_id=generatedTokenizerValue.pad_token_id
            )

        generatedDecodedValue = generatedTokenizerValue.decode(generatedOutputsValue[0], skip_special_tokens=True)
        generatedCleanDecodedValue = generatedDecodedValue.replace(generatedPromptValue, "").strip()
        generatedPrediction = generatedOutput(generatedCleanDecodedValue)

        if not np.isnan(generatedPrediction) and 0 <= generatedPrediction <= 1:
            generatedRowDictionary = generatedRowValue.to_dict()
            generatedRowDictionary["Raw_Output"] = generatedCleanDecodedValue
            generatedRowDictionary["Predicted_Inhibition"] = float(generatedPrediction)
            generatedResultsValue.append(generatedRowDictionary)

    except Exception as e:
        print(f"[ERROR] Row {idx}: {repr(e)}")

    gc.collect()
    torch.cuda.empty_cache()

generatedEndTime = time.time()
print(f"\nTotal inference time: {generatedEndTime - generatedStartTime:.2f} seconds")

generatedFinalDataFrame = pd.DataFrame(generatedResultsValue)
generatedFinalDataFrame.to_csv(generatedOutputCSV, index=False)

if 'Predicted_Inhibition' in generatedFinalDataFrame.columns and 'Inhibition(%)' in generatedFinalDataFrame.columns:
    generatedActualLabels = generatedFinalDataFrame["Inhibition(%)"].astype(float).values / 100.0
    generatedPredictionLabels = generatedFinalDataFrame["Predicted_Inhibition"].astype(float).values

    generatedRMSEValue = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nFinal RMSE: {generatedRMSEValue:.4f}")
    print(f"Final R² Score: {generatedR2Score:.4f}")
    plot_results(generatedActualLabels, generatedPredictionLabels, generatedPlotPath)
else:
    print("\nEvaluation skipped — no valid predictions.")

"""ASOptimizer Dataset - GPT-3.5-Turbo"""

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc
import re
import time
import nest_asyncio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from sklearn.utils import check_array

generatedModelName = "gpt-3.5-turbo"
generatedInputCSV = "/content/ASOptimizer.csv"
generatedOutputCSV = "/content/asoptimizer2_gpt35turbo_zeroshot.csv"
generatedClient = OpenAI(api_key=generatedAPIKey)
generatedTemperature = 1.1

def generatedSanitizedSequence(generatedSequence):
    return str(generatedSequence).strip()

def generatedOutput(generatedTextValue):
    generatedMatchesValue = re.findall(r"\b0(?:\.\d+)?|1(?:\.0+)?\b", generatedTextValue)
    for generatedMatchValue in generatedMatchesValue:
        try:
            generatedValue = float(generatedMatchValue)
            if 0 <= generatedValue <= 1:
                return round(generatedValue, 4)
        except:
            continue
    return np.nan

def generatedPromptZeroShot(generatedRowValue):
    generatedTestSequence = generatedSanitizedSequence(generatedRowValue["Sequence"])
    return (
        "You are a senior researcher in molecular biology, with deep expertise in antisense oligonucleotide (ASO) design.\n"
        "Given the DNA sequence, estimate the inhibition efficacy of gene expression.\n"
        "Consider thermodynamics, off-target effects, hybridization potential, and accessibility.\n"
        "Respond with only a number between 0 and 1 (e.g., 0.13, 0.57, 0.89).\n"
        "Avoid repeating values. Avoid values like 0.75 for every entry. Use biologically diverse reasoning.\n\n"
        f"DNA sequence: {generatedTestSequence}\n"
        f"Predicted inhibition efficacy:"
    )

nest_asyncio.apply()
generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["Sequence", "Inhibition(%)"]).reset_index(drop=True)

generatedDataFrame["Inhibition(%)"] = generatedDataFrame["Inhibition(%)"].astype(float)
generatedDataFrame["Normalized_Efficacy"] = generatedDataFrame["Inhibition(%)"] / 100.0

generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e in range(len(generatedDataFrame)):
    generatedRowValue = generatedDataFrame.iloc[e]
    generatedPromptValue = generatedPromptZeroShot(generatedRowValue)

    try:
        generatedResponseValue = generatedClient.chat.completions.create(
            model=generatedModelName,
            messages=[
                {"role": "system", "content": "You are a molecular biology expert."},
                {"role": "user", "content": generatedPromptValue}
            ],
            temperature=generatedTemperature,
            max_tokens=12
        )
        generatedResultValue = generatedResponseValue.choices[0].message.content.strip()
        generatedPredictionValue = generatedOutput(generatedResultValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedResultValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedPredictionValue

        print(f"[Row {e}] {generatedResultValue} → Parsed: {generatedPredictionValue}")
        gc.collect()
        time.sleep(1)

    except Exception as ex:
        print(f"[ERROR] Row {e}: {ex}")
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {ex}"

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Normalized_Efficacy"])
generatedValidDataFrame = generatedValidDataFrame[
    (generatedValidDataFrame["Predicted_Efficacy"] >= 0) & (generatedValidDataFrame["Predicted_Efficacy"] <= 1)
]
generatedValidDataFrame.to_csv(generatedOutputCSV, index=False)

print(f"\nTotal valid rows for evaluation: {len(generatedValidDataFrame)}")

if not generatedValidDataFrame.empty and len(generatedValidDataFrame) > 1:
    generatedActualLabels = check_array(generatedValidDataFrame["Normalized_Efficacy"], ensure_2d=False)
    generatedPredictionLabels = check_array(generatedValidDataFrame["Predicted_Efficacy"], ensure_2d=False)

    generatedRMSE = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nGPT-3.5-Turbo Zero-Shot RMSE (ASOptimizer2): {generatedRMSE:.4f}")
    print(f"GPT-3.5-Turbo Zero-Shot R² Score (ASOptimizer2): {abs(generatedR2Score):.4f}")

    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.8)
    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("True Efficacy (Normalized)")
    plt.ylabel("Predicted Efficacy")
    plt.title("GPT-3.5-Turbo Zero-Shot (ASOptimizer2): Predicted vs True Efficacy")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
else:
    print("\nNo valid predictions were found or not enough data points for R².")

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
os.makedirs("/tmp/offload", exist_ok=True)

import gc
import re
import time
import random
import nest_asyncio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from openai import OpenAI
from sklearn.utils import check_array

generatedModelName = "gpt-3.5-turbo"
generatedInputCSV = "/content/ASOptimizer.csv"
generatedOutputCSV = "/content/asoptimizer_gpt35turbo_fewshot.csv"
generatedClient = OpenAI(api_key=generatedAPIKey)
generatedTemperature = 1.1
fewShotExamples = 3

def generatedSanitizedSequence(sequence):
    return str(sequence).strip()

def extract_prediction(generatedTextValue):
    generatedMatchesValue = re.findall(r"\b0(?:\.\d+)?|1(?:\.0+)?\b", generatedTextValue)
    for generatedMatchValue in generatedMatchesValue:
        try:
            generatedValue = float(generatedMatchValue)
            if 0 <= generatedValue <= 1:
                return round(generatedValue, 4)
        except:
            continue
    return np.nan

def build_few_shot_prompt(generatedTestRow, generatedFewShotExamples):
    generatedPromptValue = (
        "You are a senior researcher in molecular biology, with deep expertise in antisense oligonucleotide (ASO) design.\n"
        "Given the DNA sequence, estimate the inhibition efficacy of gene expression.\n"
        "Consider thermodynamics, off-target effects, hybridization potential, and accessibility.\n"
        "Respond with only a number between 0 and 1 (e.g., 0.13, 0.57, 0.89).\n"
        "Avoid repeating values. Use biologically diverse reasoning.\n\n"
    )

    for _, ex in generatedFewShotExamples.iterrows():
        generatedExampleSequence = generatedSanitizedSequence(ex["Sequence"])
        generatedExampleEfficacy = round(float(ex["Inhibition(%)"]) / 100.0, 4)
        generatedPromptValue += f"DNA sequence: {generatedExampleSequence}\nPredicted inhibition efficacy: {generatedExampleEfficacy}\n\n"

    generatedTestSequence = generatedSanitizedSequence(generatedTestRow["Sequence"])
    generatedPromptValue += f"DNA sequence: {generatedTestSequence}\nPredicted inhibition efficacy:"
    return generatedPromptValue

nest_asyncio.apply()
generatedDataFrame = pd.read_csv(generatedInputCSV)
generatedDataFrame = generatedDataFrame.dropna(subset=["Sequence", "Inhibition(%)"]).reset_index(drop=True)

generatedDataFrame["Inhibition(%)"] = generatedDataFrame["Inhibition(%)"].astype(float)
generatedDataFrame["Normalized_Efficacy"] = generatedDataFrame["Inhibition(%)"] / 100.0

generatedDataFrame["Prompt"] = ""
generatedDataFrame["Model_Output"] = ""
generatedDataFrame["Predicted_Efficacy"] = np.nan

for e in range(len(generatedDataFrame)):
    generatedTestRow = generatedDataFrame.iloc[e]

    fewShotCandidates = generatedDataFrame.drop(index=e).sample(n=min(fewShotExamples, len(generatedDataFrame) - 1), random_state=None)
    generatedPromptValue = build_few_shot_prompt(generatedTestRow, fewShotCandidates)

    try:
        generatedResponseValue = generatedClient.chat.completions.create(
            model=generatedModelName,
            messages=[
                {"role": "system", "content": "You are a molecular biology expert."},
                {"role": "user", "content": generatedPromptValue}
            ],
            temperature=generatedTemperature,
            max_tokens=12
        )
        generatedResultValue = generatedResponseValue.choices[0].message.content.strip()
        generatedPredictionValue = extract_prediction(generatedResultValue)

        generatedDataFrame.at[e, "Prompt"] = generatedPromptValue
        generatedDataFrame.at[e, "Model_Output"] = generatedResultValue
        generatedDataFrame.at[e, "Predicted_Efficacy"] = generatedPredictionValue

        print(f"[Row {e}] {generatedResultValue} → Parsed: {generatedPredictionValue}")
        gc.collect()
        time.sleep(1)

    except Exception as ex:
        print(f"[ERROR] Row {e}: {ex}")
        generatedDataFrame.at[e, "Model_Output"] = f"[ERROR] {ex}"

generatedValidDataFrame = generatedDataFrame.dropna(subset=["Predicted_Efficacy", "Normalized_Efficacy"])
generatedValidDataFrame = generatedValidDataFrame[(generatedValidDataFrame["Predicted_Efficacy"] >= 0) & (generatedValidDataFrame["Predicted_Efficacy"] <= 1)]
generatedValidDataFrame.to_csv(generatedOutputCSV, index=False)

print(f"\nTotal valid rows for evaluation: {len(generatedValidDataFrame)}")

if not generatedValidDataFrame.empty and len(generatedValidDataFrame) > 1:
    generatedActualLabels = check_array(generatedValidDataFrame["Normalized_Efficacy"], ensure_2d=False)
    generatedPredictionLabels = check_array(generatedValidDataFrame["Predicted_Efficacy"], ensure_2d=False)

    generatedRMSE = np.sqrt(np.mean((generatedActualLabels - generatedPredictionLabels) ** 2))
    generatedSSResidual = np.sum((generatedActualLabels - generatedPredictionLabels) ** 2)
    generatedSSTotal = np.sum((generatedActualLabels - np.mean(generatedActualLabels)) ** 2)
    generatedR2Score = 1 - (generatedSSResidual / generatedSSTotal) if generatedSSTotal != 0 else 0.0

    print(f"\nGPT-3.5-Turbo Few-Shot RMSE (ASOptimizer): {generatedRMSE:.4f}")
    print(f"GPT-3.5-Turbo Few-Shot R² Score (ASOptimizer): {abs(generatedR2Score):.4f}")

    plt.figure(figsize=(6, 6))
    plt.scatter(generatedActualLabels, generatedPredictionLabels, alpha=0.8)
    plt.plot([0, 1], [0, 1], linestyle="--", color="gray")
    plt.xlabel("True Efficacy (Normalized)")
    plt.ylabel("Predicted Efficacy")
    plt.title("GPT-3.5-Turbo Few-Shot (ASOptimizer): Predicted vs True Efficacy")
    plt.grid(True)
    plt.tight_layout()
    plt.show()
else:
    print("\nNo valid predictions were found or not enough data points for R².")